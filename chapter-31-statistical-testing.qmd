```{r echo = FALSE, warning = FALSE}
source("init.R")
source("images/part_3/part_3_theory_testing.R")

```

# Statistical testing {#sec-temp}

*Last modified on `r format(fs::file_info("chapter-31-statistical-testing.qmd")$modification_time, '%d. %B %Y at %H:%M:%S')`*

> *"A quote." --- Dan Meyer*

## General background


```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 7
#| fig-width: 7
#| fig-cap: "foo"
#| label: data-stat-visual

ggplot() +
  theme_minimal() +
  coord_cartesian(xlim = c(-11, 11), ylim = c(-10, 10)) +
  scale_x_continuous(breaks = seq(-10,10,1)) +
  scale_y_continuous(breaks = seq(-10,10,1)) +
  geom_hline(yintercept = c(-5, 0, 5), color = "gray75") +
  geom_vline(xintercept = c(-5, 0, 5), color = "gray75") +
  ## lower
  geom_shape(data = tibble(x = c(11.5, 1.5, 1.5, 11.5), 
                           y = c(-4, -4, 2.5, 2.5)),
             aes(x, y), radius = unit(0.5, 'cm'), fill = "gray95") +
  annotate("text", x = 11.5, y = -0.75, label = "VISUALISATION", size = 5.5, fontface = 2, 
           angle = -90) +
  geom_segment(aes(x = 2.8, xend = 11, y = -3, yend = -3)) +
  geom_segment(aes(x = 3, xend = 3, y = -3.2, yend = 2)) +
  annotate("text", x = c(5, 9), y = c(-3.5, -3.5), label = c("Dog", "Cat"), 
           fontface =2) +
  annotate("text", x = c(2.3), y = c(-0.5), label = c("Jump length in [cm]"), 
           angle = 90, fontface =2) +
  ## upper left
  geom_shape(data = tibble(x = c(-11.5, -1.5, -1.5, -11.5), 
                           y = c(0.5, 0.5, 9.5, 9.5)-2.25),
             aes(x, y), radius = unit(0.5, 'cm'), fill = "gray95") +
  annotate("text", x = -11.5, y = 5-2.25, label = "DATA", size = 5.5, fontface = 2, 
           angle = 90) +
  geom_segment(aes(x = -11, xend = -2, y = 8-2.25, yend = 8-2.25)) +
  geom_segment(aes(x = -6, xend = -6, y = 9-2.25, yend = 1-2.25)) +
  geom_segment(aes(x = -8, xend = -8, y = 9-2.25, yend = 1-2.25)) + 
  annotate("text", x = c(-9.5, -7, -4), y = c(8.5)-2.25,
           label = c("id", "host", "jumplength"), fontface = 2) + 
  annotate("text", x = c(-9.5), y = c(7.5, 6.5, 5.5, 3.5, 2.5, 1.5)-2.25,
           label = c("Diana", "Doris", "Daniel", "Chloe", "Cora", "Caleb")) +
  annotate("text", x = c(-7), y = c(7.5, 6.5, 5.5, 3.5, 2.5, 1.5)-2.25,
           label = c("dog", "dog", "dog", "cat", "cat", "cat")) +
  annotate("text", x = c(-4), y = c(7.5, 6.5, 5.5, 3.5, 2.5, 1.5)-2.25,
           label = c("33.2", "31.7", "36.8", "22.1", "19.7", "24.3")) +
  annotate("point", x = c(-9.5, -9.5, -9.5, -7, -7, -7, -4, -4, -4), 
           y = c(4.3, 4.5, 4.7, 4.3, 4.5, 4.7, 4.3, 4.5, 4.7)-2.25, 
           shape = 23, fill = "black", size = 0.5) +
  ## upper right
  geom_shape(data = tibble(x = c(11.5, 1.5, 1.5, 11.5), 
                           y = c(3.5, 3.5, 9.5, 9.5)),
             aes(x, y), radius = unit(0.5, 'cm'), fill = "gray95") +
  annotate("text", x = 11.5, y = 6.5, label = "SUMMARY", size = 5.5, fontface = 2, 
           angle = -90) +
  geom_segment(aes(x = 11, xend = 2, y = 8, yend = 8)) +
  geom_segment(aes(x = 4.75, xend = 4.75, y = 9, yend = 4)) +
  annotate("text", x = c(3.5, 8), y = c(8.5),
           label = c("Host", "Descriptive statistics"), fontface = 2) +
  annotate("text", x = c(3.5), y = c(7.5, 5.5), label = c("dog", "cat")) +
  annotate("text", x = c(8), y = c(7.5, 6.5, 5.5, 4.5), 
           label = c(expression(33.9 %+-% 2.6), 
                     expression(33.2~"["*32.5*";"~"35.0"*"]"), 
                     expression("22.0" %+-% 2.3), 
                     expression(22.1~"["*20.9*";"~23.2*"]"))) 
```




```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 7
#| fig-cap: "foo"
#| label: fig-test-theory-pval-fisher
p_fisher_newman
```



```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 7
#| fig-cap: "foo"
#| label: fig-test-theory-dist
p_population_sample
```


```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 10
#| fig-cap: "foo"
#| label: fig-test-theory-random
p_theory_random
```



```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.75
#| fig-width: 10
#| fig-cap: "foo"
#| label: fig-test-theory-upper
p_theory_random_upper
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 10
#| fig-width: 10
#| fig-cap: "foo"
#| label: fig-test-theory-full
p_theory_random_full
```

## Theoretical background

### Fisher's approach: The ‘significance test’

Fisher saw statistics as a tool for inductive reasoning (learning from data for science).

-   Only ONE hypothesis: There is only the null hypothesis ($H_0$ e.g., ‘no effect’). An alternative does not formally exist.
-   The measure (p-value): The p-value is a continuous measure of the strength of evidence against the null hypothesis $H_0$.
    -   $p = 0.01$ Strong evidence against the null hypothesis.
    -   $p = 0.20$ No evidence against the null hypothesis. 
-   The result: One rejects the null hypothesis $H_0$ or one does not make a judgement. One never ‘accepts’ the null hypothesis (one simply has not found enough evidence to reject it).
-   Objective: Gain knowledge through individual experiments.

### Neyman-Pearson's approach: The ‘hypothesis test’

Neyman and Pearson sharply criticised Fisher.
They said, ‘You can't reject anything if you don't know what to accept instead.’ They saw statistics as a decision-making process (behaviourism).

-   TWO hypotheses: There is the null hypothesis ($H_0$) AND a specific alternative hypothesis ($H_A$).
-   Type 1 and 2 errors: Before the experiment begins, the following is determined:
    -   $\alpha$ (alpha): How often am I allowed to incorrectly find an effect? (e.g. 5%)
    -   $\beta$ (Beta): How often am I allowed to mistakenly overlook a real effect? (Power/test strength).
-   The result: A tough decision. ‘Accept $H_0$’ or ‘Reject $H_0$’ (or Accept $H_A$).
-   Goal: Minimisation of losses over many repeated experiments (as in industrial production).

Neymans philosophy: We are not looking for the ‘truth’ in individual cases, but rather we behave in such a way that we are wrong as rarely as possible in 1000 decisions.

### Today's ‘hybrid chaos’

Modern textbooks and software (such as SPSS or R) often use a hybrid that historically makes no sense:

-   We define $\alpha = 5\%$ (Neyman-Pearson).
-   We calculate an exact p-value (Fisher).
-   We report the p-value as evidence (Fisher), but use it for a hard yes/no decision (Neyman-Pearson).
-   We talk about ‘power’ (Neyman-Pearson), but often only test against a non-specific alternative.

This mishmash often leads to misunderstandings, such as that a $p = 0.001$ indicates a ‘stronger effect’ than $p = 0.049$  (Fisher thinking), even though in Neyman-Pearson logic at $\alpha = 5\%$ , one would have to make exactly the same decision in both cases (‘Reject $H_0$’).

## R packages used

## Data

## Alternatives

Further tutorials and R packages on XXX

## Glossary

term

:   what does it mean.

## The meaning of "Models of Reality" in this chapter.

-   itemize with max. 5-6 words

## Summary

## References {.unnumbered}
